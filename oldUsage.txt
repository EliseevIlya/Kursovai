    def __init__(self, token_file):
        self.tokens = self.read_tokens(token_file)
        self.current_token = None
        self.index = -1
        self.next_token()

    def read_tokens(self, token_file):
        with open(token_file, 'r') as f:
            data = f.read().strip()
        # Разделение строки на токены вида (n, k)
        tokens = data.replace(")(", ") (").split()  # разделяем токены
        return [eval(token) for token in tokens]  # превращаем строку '(n, k)' в кортежи (n, k)

    def next_token(self):
        self.index += 1
        if self.index < len(self.tokens):
            self.current_token = self.tokens[self.index]
        else:
            self.current_token = None  # EOF


    ''''def __init__(self, lexer):
        self.lexer = lexer
        self.current_token = None
        self.next_token()

    def next_token(self):
        self.current_token = self.lexer.get_next_token()'''''

    def parse(self):
        """ <программа>::= «{» {/ (<описание> | <оператор>) ; /} «}» """
        if self.current_token == (2, 14):  # '{'
            self.next_token()
            while self.current_token != (2, 16):  # ';}'
                if self.current_token in [(1, 1), (1, 6), (1, 9), (1, 10)]:
                    self.parse_operator()
                else:
                    self.parse_declaration()
                if self.current_token == (2, 16):  # ';'
                    self.next_token()
            if self.current_token == (2, 15):  # '}'
                self.next_token()
            else:
                raise SyntaxError("Программа должна завершаться '}'")
        else:
            raise SyntaxError("Программа должна начинаться с '{'")
